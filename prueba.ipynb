{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_smodel import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2000, 0.8000],\n",
      "         [0.5000, 0.5000],\n",
      "         [0.7000, 0.3000]],\n",
      "\n",
      "        [[0.1000, 0.9000],\n",
      "         [0.6000, 0.4000],\n",
      "         [0.8000, 0.2000]],\n",
      "\n",
      "        [[0.3000, 0.7000],\n",
      "         [0.4000, 0.6000],\n",
      "         [0.9000, 0.1000]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Supongamos que tienes una matriz cuadrada de 3x3\n",
    "matrix = [[0.2, 0.5, 0.7], [0.1, 0.6, 0.8], [0.3, 0.4, 0.9]]\n",
    "\n",
    "# Creamos un tensor de PyTorch a partir de la matriz\n",
    "tensor = torch.tensor(matrix)\n",
    "\n",
    "# Calculamos el complementario de cada elemento del tensor\n",
    "complementary = 1 - tensor\n",
    "\n",
    "# Concatenamos el tensor y su complementario en una única matriz\n",
    "vectors = torch.stack([tensor, complementary], dim=-1)\n",
    "\n",
    "# Aplanamos la matriz de vectores en un array de una única columna\n",
    "array = vectors.flatten().view((3,3,2))\n",
    "\n",
    "# Imprimimos el array por pantalla\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.]],\n",
       "\n",
       "        [[0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.]],\n",
       "\n",
       "        [[1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#F.gumbel_softmax(array.view(3,3,2), tau=0.5, hard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6094, -0.2231],\n",
       "         [-0.6931, -0.6931],\n",
       "         [-0.3567, -1.2040]],\n",
       "\n",
       "        [[-2.3026, -0.1054],\n",
       "         [-0.5108, -0.9163],\n",
       "         [-0.2231, -1.6094]],\n",
       "\n",
       "        [[-1.2040, -0.3567],\n",
       "         [-0.9163, -0.5108],\n",
       "         [-0.1054, -2.3026]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = array.log()\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8035, 0.2317, 0.6279],\n",
       "         [0.8268, 0.8375, 0.0307],\n",
       "         [0.2889, 0.3375, 0.5076]]),\n",
       " tensor([[0.8035, 0.8268, 0.2889],\n",
       "         [0.2317, 0.8375, 0.3375],\n",
       "         [0.6279, 0.0307, 0.5076]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Crea un tensor de shape (3, 3, 5) con valores aleatorios\n",
    "A = torch.rand((3, 3, 5))\n",
    "A_t = torch.transpose(A, 0, 1)\n",
    "# Crea un tensor de shape (3, 3, 5) lleno de ceros\n",
    "#B = torch.zeros_like(A)\n",
    "\n",
    "# Itera a través de las primeras dos dimensiones de A\n",
    "\n",
    "A[:,:,3], A_t[:,:,3]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = F.gumbel_softmax(logits=logits, tau=0.5, hard=True)\n",
    "for i in range(9999):\n",
    "    v += F.gumbel_softmax(logits=logits, tau=0.1, hard=True)\n",
    "v = v/9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1989, 0.8012],\n",
       "         [0.4961, 0.5040],\n",
       "         [0.6962, 0.3039]],\n",
       "\n",
       "        [[0.0988, 0.9013],\n",
       "         [0.5976, 0.4025],\n",
       "         [0.8165, 0.1836]],\n",
       "\n",
       "        [[0.3026, 0.6975],\n",
       "         [0.3938, 0.6063],\n",
       "         [0.8986, 0.1015]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7950],\n",
       "        [0.5037],\n",
       "        [0.3044],\n",
       "        [0.8988],\n",
       "        [0.3980],\n",
       "        [0.1990],\n",
       "        [0.7021],\n",
       "        [0.5999],\n",
       "        [0.0975]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = v[:, 1].unsqueeze(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 3, 3, 1, 4, 2, 3, 2, 3], dtype=torch.int8),\n",
       " tensor([0.5688, 0.4614, 3.9108, 3.2038, 0.7585, 5.8441, 2.5679, 3.5997, 1.8629,\n",
       "         4.5957], dtype=torch.float64))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta = torch.from_numpy(np.random.uniform(low=0, high=2*np.pi, size=10))\n",
    "Q_ = (Theta/(np.pi/2) + 1).type(torch.int8)\n",
    "Q_, Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.2500, 0.0000, 0.2500, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.zeros(7,7, dtype=torch.float64)\n",
    "p[2:5,2:5] = 0.25\n",
    "p[3,3] = 0\n",
    "p[2:5, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 1, 1, 1, 0],\n",
       "         [0, 1, 1, 0, 0],\n",
       "         [1, 0, 0, 1, 0]]),\n",
       " tensor([[[1, 1, 0],\n",
       "          [0, 0, 0],\n",
       "          [1, 0, 1],\n",
       "          [1, 1, 1],\n",
       "          [0, 1, 0]],\n",
       " \n",
       "         [[0, 1, 1],\n",
       "          [1, 0, 0],\n",
       "          [1, 1, 1],\n",
       "          [0, 1, 1],\n",
       "          [0, 1, 1]],\n",
       " \n",
       "         [[0, 0, 1],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 0],\n",
       "          [1, 0, 1],\n",
       "          [0, 0, 1]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 1, 1],\n",
       "          [0, 1, 0],\n",
       "          [1, 1, 1],\n",
       "          [1, 0, 1]],\n",
       " \n",
       "         [[0, 1, 1],\n",
       "          [0, 0, 0],\n",
       "          [1, 0, 1],\n",
       "          [1, 0, 0],\n",
       "          [0, 1, 1]]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.randint(size=(5, 5), low=0, high=2)\n",
    "S = torch.randint(size=(5, 5, 3), low=0, high=2)\n",
    "s, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False,  True,  True,  True, False],\n",
       "        [False,  True,  True, False, False],\n",
       "        [ True, False, False,  True, False]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "s = torch.randint(size=(7, 7), low=0, high=2)\n",
    "prob = torch.zeros((7,7), dtype=torch.float64)\n",
    "prob[1:-1, 1:-1] = torch.rand(size=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\joanb\\Desktop\\PyTorch\\prueba.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joanb/Desktop/PyTorch/prueba.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39mwhere(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joanb/Desktop/PyTorch/prueba.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     torch\u001b[39m.\u001b[39mlogical_and(s\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m, torch\u001b[39m.\u001b[39mlogical_and(prob \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m, prob \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)),\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/joanb/Desktop/PyTorch/prueba.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     F\u001b[39m.\u001b[39mgumbel_softmax(torch\u001b[39m.\u001b[39;49mTensor([prob, \u001b[39m1\u001b[39;49m\u001b[39m-\u001b[39;49mprob])\u001b[39m.\u001b[39mlog(), hard\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joanb/Desktop/PyTorch/prueba.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     s\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joanb/Desktop/PyTorch/prueba.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.where(\n",
    "    torch.logical_and(s==0, torch.logical_and(prob < 1, prob > 0)),\n",
    "    F.gumbel_softmax(torch.Tensor([prob, 1-prob]).log(), hard=True)[1],\n",
    "    s\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.gumbel_softmax(torch.rand(size=(3,3)), tau=0.5, hard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([Q(b) for b in Theta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2, 1, 3, 3, 2, 2, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8942931076307636,\n",
       " 1.1545557279496679,\n",
       " 0.6847635950931208,\n",
       " 0.6653992502420045,\n",
       " 1.5128355186342448,\n",
       " 1.1647281208341003,\n",
       " 1.160027115070257,\n",
       " 1.1868851678213792,\n",
       " 0.7155524198920187,\n",
       " 0.24115321182122118]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_theta = [T(b) for b in Theta]\n",
    "T_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8943, 1.1546, 0.6848, 0.6654, 1.5128, 1.1647, 1.1600, 1.1869, 0.7156,\n",
       "        0.2412], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(\n",
    "    torch.logical_or(torch.from_numpy(Q_) == 1, torch.from_numpy(Q_) == 3),\n",
    "    #Q in [1,3],\n",
    "    torch.from_numpy(Theta - ((Q_-1)/2)*torch.pi),\n",
    "    torch.from_numpy((Q_/2)*torch.pi - Theta)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8942931076307636,\n",
       " 1.1545557279496679,\n",
       " 0.6847635950931208,\n",
       " 0.6653992502420045,\n",
       " 1.5128355186342448,\n",
       " 1.1647281208341003,\n",
       " 1.160027115070257,\n",
       " 1.1868851678213792,\n",
       " 0.7155524198920187,\n",
       " 0.24115321182122118]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Theta', 'Quadrant', 'Xi', 'Rho', 'm', 'Susceptibles', 'Infecteds', 'Deads']\n",
    "df = pd.DataFrame(index = range(10 + 1), columns = columnas)\n",
    "df.iloc[0] = [None, None, None, None, None, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Theta[1:]=torch.tensor(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Theta[0:3] = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Theta</th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>Xi</th>\n",
       "      <th>Rho</th>\n",
       "      <th>m</th>\n",
       "      <th>Susceptibles</th>\n",
       "      <th>Infecteds</th>\n",
       "      <th>Deads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Theta Quadrant    Xi   Rho     m Susceptibles Infecteds Deads\n",
       "0      1     None  None  None  None            1         1     1\n",
       "1      2      NaN   NaN   NaN   NaN          NaN       NaN   NaN\n",
       "2      3      NaN   NaN   NaN   NaN          NaN       NaN   NaN\n",
       "3      2      NaN   NaN   NaN   NaN          NaN       NaN   NaN\n",
       "4      3      NaN   NaN   NaN   NaN          NaN       NaN   NaN\n",
       "5      4      NaN   NaN   NaN   NaN          NaN       NaN   NaN\n",
       "6      5      NaN   NaN   NaN   NaN          NaN       NaN   NaN\n",
       "7      6      NaN   NaN   NaN   NaN          NaN       NaN   NaN\n",
       "8      7      NaN   NaN   NaN   NaN          NaN       NaN   NaN\n",
       "9      8      NaN   NaN   NaN   NaN          NaN       NaN   NaN\n",
       "10     9      NaN   NaN   NaN   NaN          NaN       NaN   NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8852db887e4898adf41e8dfeeeb2275e3a600f3c56ac76bec9205a61cab2c77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
